{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ7envxakfn8Lt+g8cEE6R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirmohammadkalateh/colony_counter/blob/main/colony_count_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG_GyhQHse1L",
        "outputId": "c8de5601-a832-483a-d54c-86cb84167f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not read image at path/to/image1.jpg\n",
            "Error: Could not read image at path/to/image2.jpg\n",
            "Error: Could not read image at path/to/image3.jpg\n",
            "No images were loaded. Please check the image paths and colony counts.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def load_and_preprocess_data(image_paths, colony_counts, image_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    Loads images from given paths, preprocesses them, and prepares the data for training.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of paths to the image files.\n",
        "        colony_counts (list): List of corresponding colony counts for each image.\n",
        "        image_size (tuple): The target size (width, height) to resize the images.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - X (numpy.ndarray): Array of preprocessed image data.\n",
        "            - y (numpy.ndarray): Array of colony counts.\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = [] # Initialize y as an empty list\n",
        "    for i, image_path in enumerate(image_paths): # Use enumerate to get the index\n",
        "        try:\n",
        "            # Load the image in grayscale\n",
        "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                print(f\"Error: Could not read image at {image_path}\")\n",
        "                continue  # Skip to the next image\n",
        "            # Resize the image\n",
        "            img = cv2.resize(img, image_size)\n",
        "            # Normalize pixel values to be between 0 and 1\n",
        "            img = img / 255.0\n",
        "            X.append(img)\n",
        "            y.append(colony_counts[i]) # Append the corresponding count\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {image_path}: {e}\")\n",
        "            continue  # Skip to the next image on error\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    return X, y\n",
        "\n",
        "def create_model(input_shape):\n",
        "    \"\"\"\n",
        "    Creates a simple feedforward neural network model using Keras.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): Shape of the input data (e.g., (128, 128, 1) for grayscale images).\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: The compiled neural network model.\n",
        "    \"\"\"\n",
        "    model = keras.Sequential([\n",
        "        # Flatten the 2D image data to a 1D vector\n",
        "        keras.layers.Flatten(input_shape=input_shape),\n",
        "        # Fully connected layer with 128 neurons and ReLU activation\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        # Fully connected layer with 64 neurons and ReLU activation\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        # Output layer with 1 neuron for predicting the colony count\n",
        "        keras.layers.Dense(1, activation='linear')  # Use linear activation for regression\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae']) # mae is Mean Absolute Error\n",
        "    return model\n",
        "\n",
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=10, batch_size=32):\n",
        "    \"\"\"\n",
        "    Trains the neural network model.\n",
        "\n",
        "    Args:\n",
        "        model (keras.Model): The neural network model to train.\n",
        "        X_train (numpy.ndarray): Training data.\n",
        "        y_train (numpy.ndarray): Training labels (colony counts).\n",
        "        X_val (numpy.ndarray): Validation data.\n",
        "        y_val (numpy.ndarray): Validation labels (colony counts).\n",
        "        epochs (int): Number of training epochs.\n",
        "        batch_size (int): Batch size for training.\n",
        "\n",
        "    Returns:\n",
        "        History: The training history object.\n",
        "    \"\"\"\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(X_val, y_val),\n",
        "        verbose=1\n",
        "    )\n",
        "    return history\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Evaluates the trained neural network model on the test data.\n",
        "\n",
        "    Args:\n",
        "        model (keras.Model): The trained neural network model.\n",
        "        X_test (numpy.ndarray): Test data.\n",
        "        y_test (numpy.ndarray): Test labels (colony counts).\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Evaluate the model on the test data\n",
        "    loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"Test Loss: {loss:.4f}\")\n",
        "    print(f\"Test Mean Absolute Error: {mae:.4f}\")\n",
        "\n",
        "def predict_colony_count(model, image_path, image_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    Predicts the colony count for a single image.\n",
        "\n",
        "    Args:\n",
        "        model (keras.Model): The trained neural network model.\n",
        "        image_path (str): Path to the image file.\n",
        "        image_size (tuple): The target size to resize the image.\n",
        "\n",
        "    Returns:\n",
        "        int: The predicted colony count.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load and preprocess the image\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Could not read image at {image_path}\")\n",
        "        img = cv2.resize(img, image_size)\n",
        "        img = img / 255.0\n",
        "        img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "        # Make a prediction\n",
        "        prediction = model.predict(img)\n",
        "        # Round the prediction to the nearest integer\n",
        "        colony_count = int(round(prediction[0][0]))\n",
        "        return colony_count\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {image_path}: {e}\")\n",
        "        return -1  # Return -1 to indicate an error\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the colony counting pipeline.\n",
        "    \"\"\"\n",
        "    # 1. Prepare your data:\n",
        "    #    - Collect a dataset of bacterial colony images and their corresponding colony counts.\n",
        "    #    - Store the image paths and counts in lists.  For example:\n",
        "    image_paths = [\n",
        "        \"path/to/image1.jpg\",\n",
        "        \"path/to/image2.jpg\",\n",
        "        \"path/to/image3.jpg\",\n",
        "        # Add more image paths...\n",
        "    ]\n",
        "    colony_counts = [25, 12, 30, ...]  # Corresponding colony counts\n",
        "\n",
        "    # 2. Load and preprocess the data\n",
        "    X, y = load_and_preprocess_data(image_paths, colony_counts)\n",
        "\n",
        "    # 3. Split the data into training, validation, and test sets\n",
        "    if len(X) > 0: # Check if X is not empty\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 of 0.8 = 0.2\n",
        "\n",
        "        # Reshape the training data to add the channel dimension (for grayscale, it's 1)\n",
        "        X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "        X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)\n",
        "        X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
        "        input_shape = X_train.shape[1:] # (128, 128, 1)\n",
        "\n",
        "         # Scale the features\n",
        "        scaler = MinMaxScaler()\n",
        "        X_train = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1)).reshape(X_train.shape)\n",
        "        X_val = scaler.transform(X_val.reshape(X_val.shape[0], -1)).reshape(X_val.shape)\n",
        "        X_test = scaler.transform(X_test.reshape(X_test.shape[0], -1)).reshape(X_test.shape)\n",
        "\n",
        "        # 4. Create the model\n",
        "        model = create_model(input_shape)\n",
        "\n",
        "        # 5. Train the model\n",
        "        history = train_model(model, X_train, y_train, X_val, y_val, epochs=50, batch_size=32) # Increased epochs for better learning\n",
        "\n",
        "        # 6. Evaluate the model\n",
        "        evaluate_model(model, X_test, y_test)\n",
        "\n",
        "        # 7. Make a prediction for a single image\n",
        "        test_image_path = \"path/to/your/test_image.jpg\"  # Replace with a path to a test image\n",
        "        predicted_count = predict_colony_count(model, test_image_path)\n",
        "        if predicted_count != -1:\n",
        "            print(f\"Predicted colony count for {test_image_path}: {predicted_count}\")\n",
        "    else:\n",
        "        print(\"No images were loaded. Please check the image paths and colony counts.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def load_and_preprocess_data(image_paths, colony_counts, image_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    Loads images from given paths, preprocesses them, and prepares the data for training.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of paths to the image files.\n",
        "        colony_counts (list): List of corresponding colony counts for each image.\n",
        "        image_size (tuple): The target size (width, height) to resize the images.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - X (numpy.ndarray): Array of preprocessed image data.\n",
        "            - y (numpy.ndarray): Array of colony counts.\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = [] # Initialize y as an empty list\n",
        "    for i, image_path in enumerate(image_paths): # Use enumerate to get the index\n",
        "        try:\n",
        "            # Load the image in grayscale\n",
        "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                print(f\"Error: Could not read image at {image_path}\")\n",
        "                continue  # Skip to the next image\n",
        "            # Resize the image\n",
        "            img = cv2.resize(img, image_size)\n",
        "            # Normalize pixel values to be between 0 and 1\n",
        "            img = img / 255.0\n",
        "            X.append(img)\n",
        "            y.append(colony_counts[i]) # Append the corresponding count\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {image_path}: {e}\")\n",
        "            continue  # Skip to the next image on error\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    return X, y\n",
        "\n",
        "def create_model(input_shape):\n",
        "    \"\"\"\n",
        "    Creates a simple feedforward neural network model using Keras.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): Shape of the input data (e.g., (128, 128, 1) for grayscale images).\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: The compiled neural network model.\n",
        "    \"\"\"\n",
        "    model = keras.Sequential([\n",
        "        # Flatten the 2D image data to a 1D vector\n",
        "        keras.layers.Flatten(input_shape=input_shape),\n",
        "        # Fully connected layer with 128 neurons and ReLU activation\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        # Fully connected layer with 64 neurons and ReLU activation\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        # Output layer with 1 neuron for predicting the colony count\n",
        "        keras.layers.Dense(1, activation='linear')  # Use linear activation for regression\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae']) # mae is Mean Absolute Error\n",
        "    return model\n",
        "\n",
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=10, batch_size=32):\n",
        "    \"\"\"\n",
        "    Trains the neural network model.\n",
        "\n",
        "    Args:\n",
        "        model (keras.Model): The neural network model to train.\n",
        "        X_train (numpy.ndarray): Training data.\n",
        "        y_train (numpy.ndarray): Training labels (colony counts).\n",
        "        X_val (numpy.ndarray): Validation data.\n",
        "        y_val (numpy.ndarray): Validation labels (colony counts).\n",
        "        epochs (int): Number of training epochs.\n",
        "        batch_size (int): Batch size for training.\n",
        "\n",
        "    Returns:\n",
        "        History: The training history object.\n",
        "    \"\"\"\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(X_val, y_val),\n",
        "        verbose=1\n",
        "    )\n",
        "    return history\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Evaluates the trained neural network model on the test data.\n",
        "\n",
        "    Args:\n",
        "        model (keras.Model): The trained neural network model.\n",
        "        X_test (numpy.ndarray): Test data.\n",
        "        y_test (numpy.ndarray): Test labels (colony counts).\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Evaluate the model on the test data\n",
        "    loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"Test Loss: {loss:.4f}\")\n",
        "    print(f\"Test Mean Absolute Error: {mae:.4f}\")\n",
        "\n",
        "def predict_colony_count(model, image_path, image_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    Predicts the colony count for a single image.\n",
        "\n",
        "    Args:\n",
        "        model (keras.Model): The trained neural network model.\n",
        "        image_path (str): Path to the image file.\n",
        "        image_size (tuple): The target size to resize the image.\n",
        "\n",
        "    Returns:\n",
        "        int: The predicted colony count.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load and preprocess the image\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Could not read image at {image_path}\")\n",
        "        img = cv2.resize(img, image_size)\n",
        "        img = img / 255.0\n",
        "        img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "        # Make a prediction\n",
        "        prediction = model.predict(img)\n",
        "        # Round the prediction to the nearest integer\n",
        "        colony_count = int(round(prediction[0][0]))\n",
        "        return colony_count\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {image_path}: {e}\")\n",
        "        return -1  # Return -1 to indicate an error\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the colony counting pipeline.\n",
        "    \"\"\"\n",
        "    # 1. Prepare your data:\n",
        "    #    - Collect a dataset of bacterial colony images and their corresponding colony counts.\n",
        "    #    - Store the image paths and counts in lists.  For example:\n",
        "    image_paths = [\n",
        "        \"path/to/image1.jpg\",\n",
        "        \"path/to/image2.jpg\",\n",
        "        \"path/to/image3.jpg\",\n",
        "        # Add more image paths...\n",
        "    ]\n",
        "    colony_counts = [25, 12, 30, ...]  # Corresponding colony counts\n",
        "\n",
        "    # 2. Load and preprocess the data\n",
        "    X, y = load_and_preprocess_data(image_paths, colony_counts)\n",
        "\n",
        "    # 3. Split the data into training, validation, and test sets\n",
        "    if len(X) > 0: # Check if X is not empty\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 of 0.8 = 0.2\n",
        "\n",
        "        # Reshape the training data to add the channel dimension (for grayscale, it's 1)\n",
        "        if len(X_train.shape) == 3:\n",
        "            X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "            X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)\n",
        "            X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
        "        elif len(X_train.shape) == 4:\n",
        "            X_train = X_train\n",
        "            X_val = X_val\n",
        "            X_test = X_test\n",
        "        else:\n",
        "            print(\"Unexpected shape for input data.  Exiting.\")\n",
        "            return\n",
        "        input_shape = X_train.shape[1:] # (128, 128, 1)\n",
        "\n",
        "         # Scale the features\n",
        "        scaler = MinMaxScaler()\n",
        "        X_train = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1)).reshape(X_train.shape)\n",
        "        X_val = scaler.transform(X_val.reshape(X_val.shape[0], -1)).reshape(X_val.shape)\n",
        "        X_test = scaler.transform(X_test.reshape(X_test.shape[0], -1)).reshape(X_test.shape)\n",
        "\n",
        "        # 4. Create the model\n",
        "        model = create_model(input_shape)\n",
        "\n",
        "        # 5. Train the model\n",
        "        history = train_model(model, X_train, y_train, X_val, y_val, epochs=50, batch_size=32) # Increased epochs for better learning\n",
        "\n",
        "        # 6. Evaluate the model\n",
        "        evaluate_model(model, X_test, y_test)\n",
        "\n",
        "        # 7. Make a prediction for a single image\n",
        "        test_image_path = \"path/to/your/test_image.jpg\"  # Replace with a path to a test image\n",
        "        predicted_count = predict_colony_count(model, test_image_path)\n",
        "        if predicted_count != -1:\n",
        "            print(f\"Predicted colony count for {test_image_path}: {predicted_count}\")\n",
        "    else:\n",
        "        print(\"No images were loaded. Please check the image paths and colony counts.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqTGKC-XtIZC",
        "outputId": "d94a72f5-888e-4fc3-8f93-b25c468ced73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not read image at path/to/image1.jpg\n",
            "Error: Could not read image at path/to/image2.jpg\n",
            "Error: Could not read image at path/to/image3.jpg\n",
            "No images were loaded. Please check the image paths and colony counts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def load_and_preprocess_data(image_paths, colony_counts, image_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    Loads images from given paths, preprocesses them, and prepares the data for training.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of paths to the image files.\n",
        "        colony_counts (list): List of corresponding colony counts for each image.\n",
        "        image_size (tuple): The target size (width, height) to resize the images.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - X (numpy.ndarray): Array of preprocessed image data.\n",
        "            - y (numpy.ndarray): Array of colony counts.\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = [] # Initialize y as an empty list\n",
        "    for i, image_path in enumerate(image_paths): # Use enumerate to get the index\n",
        "        try:\n",
        "            # Load the image in grayscale\n",
        "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                print(f\"Error: Could not read image at {image_path}\")\n",
        "                continue  # Skip to the next image\n",
        "            # Resize the image\n",
        "            img = cv2.resize(img, image_size)\n",
        "            # Normalize pixel values to be between 0 and 1\n",
        "            img = img / 255.0\n",
        "            X.append(img)\n",
        "            y.append(colony_counts[i]) # Append the corresponding count\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {image_path}: {e}\")\n",
        "            continue  # Skip to the next image on error\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    return X, y\n",
        "\n",
        "def create_model(input_shape):\n",
        "    \"\"\"\n",
        "    Creates a simple feedforward neural network model using Keras.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): Shape of the input data (e.g., (128, 128, 1) for grayscale images).\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: The compiled neural network model.\n",
        "    \"\"\"\n",
        "    model = keras.Sequential([\n",
        "        # Flatten the 2D image data to a 1D vector\n",
        "        keras.layers.Flatten(input_shape=input_shape),\n",
        "        # Fully connected layer with 128 neurons and ReLU activation\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        # Fully connected layer with 64 neurons and ReLU activation\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        # Output layer with 1 neuron for predicting the colony count\n",
        "        keras.layers.Dense(1, activation='linear')  # Use linear activation for regression\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae']) # mae is Mean Absolute Error\n",
        "    return model\n",
        "\n",
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=10, batch_size=32):\n",
        "    \"\"\"\n",
        "    Trains the neural network model.\n",
        "\n",
        "    Args:\n",
        "        model (keras.Model): The neural network model to train.\n",
        "        X_train (numpy.ndarray): Training data.\n",
        "        y_train (numpy.ndarray): Training labels (colony counts).\n",
        "        X_val (numpy.ndarray): Validation data.\n",
        "        y_val (numpy.ndarray): Validation labels (colony counts).\n",
        "        epochs (int): Number of training epochs.\n",
        "        batch_size (int): Batch size for training.\n",
        "\n",
        "    Returns:\n",
        "        History: The training history object.\n",
        "    \"\"\"\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(X_val, y_val),\n",
        "        verbose=1\n",
        "    )\n",
        "    return history\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Evaluates the trained neural network model on the test data.\n",
        "\n",
        "    Args:\n",
        "        model (keras.Model): The trained neural network model.\n",
        "        X_test (numpy.ndarray): Test data.\n",
        "        y_test (numpy.ndarray): Test labels (colony counts).\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Evaluate the model on the test data\n",
        "    loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"Test Loss: {loss:.4f}\")\n",
        "    print(f\"Test Mean Absolute Error: {mae:.4f}\")\n",
        "\n",
        "def predict_colony_count(model, image_path, image_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    Predicts the colony count for a single image.\n",
        "\n",
        "    Args:\n",
        "        model (keras.Model): The trained neural network model.\n",
        "        image_path (str): Path to the image file.\n",
        "        image_size (tuple): The target size to resize the image.\n",
        "\n",
        "    Returns:\n",
        "        int: The predicted colony count.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load and preprocess the image\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Could not read image at {image_path}\")\n",
        "        img = cv2.resize(img, image_size)\n",
        "        img = img / 255.0\n",
        "        img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "        # Make a prediction\n",
        "        prediction = model.predict(img)\n",
        "        # Round the prediction to the nearest integer\n",
        "        colony_count = int(round(prediction[0][0]))\n",
        "        return colony_count\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {image_path}: {e}\")\n",
        "        return -1  # Return -1 to indicate an error\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the colony counting pipeline.\n",
        "    \"\"\"\n",
        "    # 1. Prepare your data:\n",
        "    #    - Collect a dataset of bacterial colony images and their corresponding colony counts.\n",
        "    #    - Store the image paths and counts in lists.  For example:\n",
        "    image_paths = [\n",
        "        \"path/to/image1.jpg\",  # Replace with your actual image paths\n",
        "        \"path/to/image2.jpg\",\n",
        "        \"path/to/image3.jpg\",\n",
        "        # Add more image paths...\n",
        "    ]\n",
        "    colony_counts = [25, 12, 30, ...]  # Corresponding colony counts\n",
        "\n",
        "    # 2. Load and preprocess the data\n",
        "    X, y = load_and_preprocess_data(image_paths, colony_counts)\n",
        "\n",
        "    # 3. Split the data into training, validation, and test sets\n",
        "    if len(X) > 0: # Check if X is not empty\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 of 0.8 = 0.2\n",
        "\n",
        "        # Reshape the training data to add the channel dimension (for grayscale, it's 1)\n",
        "        if len(X_train.shape) == 3:\n",
        "            X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "            X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)\n",
        "            X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
        "        elif len(X_train.shape) == 4:\n",
        "            X_train = X_train\n",
        "            X_val = X_val\n",
        "            X_test = X_test\n",
        "        else:\n",
        "            print(\"Unexpected shape for input data.  Exiting.\")\n",
        "            return\n",
        "        input_shape = X_train.shape[1:] # (128, 128, 1)\n",
        "\n",
        "         # Scale the features\n",
        "        scaler = MinMaxScaler()\n",
        "        X_train = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1)).reshape(X_train.shape)\n",
        "        X_val = scaler.transform(X_val.reshape(X_val.shape[0], -1)).reshape(X_val.shape)\n",
        "        X_test = scaler.transform(X_test.reshape(X_test.shape[0], -1)).reshape(X_test.shape)\n",
        "\n",
        "        # 4. Create the model\n",
        "        model = create_model(input_shape)\n",
        "\n",
        "        # 5. Train the model\n",
        "        history = train_model(model, X_train, y_train, X_val, y_val, epochs=50, batch_size=32) # Increased epochs for better learning\n",
        "\n",
        "        # 6. Evaluate the model\n",
        "        evaluate_model(model, X_test, y_test)\n",
        "\n",
        "        # 7. Make a prediction for a single image\n",
        "        test_image_path = \"path/to/your/test_image.jpg\"  # Replace with a path to a test image\n",
        "        predicted_count = predict_colony_count(model, test_image_path)\n",
        "        if predicted_count != -1:\n",
        "            print(f\"Predicted colony count for {test_image_path}: {predicted_count}\")\n",
        "    else:\n",
        "        print(\"No images were loaded. Please check the image paths and colony counts.\")\n",
        "        print(\"Make sure the paths in the 'image_paths' list are correct and that the images exist at those locations.\") # Added debug message\n",
        "        print(\"Also, ensure that the 'colony_counts' list has the same number of elements as the 'image_paths' list.\") # Added debug message\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trt2Unq6tcAs",
        "outputId": "0a70fd66-1c7e-41b4-b652-048645960a5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not read image at path/to/image1.jpg\n",
            "Error: Could not read image at path/to/image2.jpg\n",
            "Error: Could not read image at path/to/image3.jpg\n",
            "No images were loaded. Please check the image paths and colony counts.\n",
            "Make sure the paths in the 'image_paths' list are correct and that the images exist at those locations.\n",
            "Also, ensure that the 'colony_counts' list has the same number of elements as the 'image_paths' list.\n"
          ]
        }
      ]
    }
  ]
}